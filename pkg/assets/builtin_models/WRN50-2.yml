name: WRN50 # name of your model
framework:
  name: MXNet # framework for the model
  version: 0.11.0 # framework version contraint
version: 2.0 # version information in semantic version format
container: # containers used to perform model prediction
           # multiple platforms can be specified
  amd64:
    gpu: raiproject/carml-caffe:amd64-cpu
    cpu: raiproject/carml-caffe:amd64-gpu
  ppc64le:
    cpu: raiproject/carml-caffe:ppc64le-gpu
    gpu: raiproject/carml-caffe:ppc64le-gpu
description: >
  This model was used for experiments with Wide Residual Networks (BMVC 2016) http://arxiv.org/abs/1605.07146 by Sergey Zagoruyko and Nikos Komodakis.
  Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent
  of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse,
  which makes these networks very slow to train. To tackle these problems, in this work we conduct a detailed experimental study on the architecture of ResNet blocks,
  based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs)
  and show that these are far superior over their commonly used thin and very deep counterparts
references: # references to papers / websites / etc.. describing the model
  - https://github.com/soeaver/caffe-model/tree/master/cls
  - https://arxiv.org/abs/1605.07146
  - https://github.com/szagoruyko/wide-residual-networks
  - https://github.com/szagoruyko/functional-zoo/blob/master/imagenet-validation.py#L69-L88
# license of the model
license: unrestricted
# inputs to the model
inputs:
  # first input type for the model
  - type: image
    # description of the first input
    description: the input image
    parameters: # type parameters
      dimensions: [3, 224, 224]
      mean: [123.68, 116.779, 103.939]
      scale: 256
output:
  # the type of the output
  type: feature
  # a description of the output parameter
  description: the output label
  parameters:
    # type parameters
    features_url: http://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset.txt
    features_checksum: 4d234b5833aca44928065a180db3016a
model: # specifies model graph and weights resources
  graph_path: http://s3.amazonaws.com/store.carml.org/models/mxnet/wrn50-2/wrn50-2-symbol.json
  weights_path: http://s3.amazonaws.com/store.carml.org/models/mxnet/wrn50-2/wrn50-2-0000.params
  is_archive: false # if set, then the base_url is a url to an archive
                    # the graph_path and weights_path then denote the
                    # file names of the graph and weights within the archive
  graph_checksum: 3004867b5176493e8c81fdb781d28af2
  weights_checksum: 2e9c34d1c507b0eb75f46970f5ff6a89
attributes: # extra network attributes
  kind: CNN # the kind of neural network (CNN, RNN, ...)
  training_dataset: ImageNet # dataset used to for training
  manifest_author: abduld
